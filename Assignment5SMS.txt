import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split,cross_val_score, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score,confusion_matrix
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv('SMSSpamCollection.csv', sep='\t', names=['label', 'message'])

data.head()

data.shape

data.columns

data.isnull().sum()

label_encoder = LabelEncoder()
data['label'] = label_encoder.fit_transform(data['label'])

data.head()

# Text Transformation
vectorizer = TfidfVectorizer()
X = vectorizer.fit_transform(data['message'])
y = data['label']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Naive Bayes Classifier
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
y_pred_nb = nb_model.predict(X_test)
accuracy_nb = accuracy_score(y_test, y_pred_nb)
print("Naive Bayes Accuracy:", accuracy_nb)
report_nb = classification_report(y_test, y_pred_nb, output_dict=True)

confusion_nb = confusion_matrix(y_test, y_pred_nb)

def plot_confusion_matrix(cm, model_name):
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
    plt.title(f'Confusion Matrix for {model_name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

plot_confusion_matrix(confusion_nb, 'Naive Bayes')

lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)
accuracy_lr = accuracy_score(y_test, y_pred_lr)
print("Logistic Regression Accuracy:", accuracy_lr)
report_lr = classification_report(y_test, y_pred_lr, output_dict=True)
print("Classification Report:\n", report_lr)

confusion_lr = confusion_matrix(y_test, y_pred_lr)

plot_confusion_matrix(confusion_lr, 'Logistic Regression')

nb_cv_scores = cross_val_score(nb_model, X, y, cv=5)
lr_cv_scores = cross_val_score(lr_model, X, y, cv=5)
print("Naive Bayes CV Scores:", nb_cv_scores.mean())
print("Logistic Regression CV Scores:", lr_cv_scores.mean())

param_grid = {'alpha': [0.1, 0.5, 1.0]}
grid_search = GridSearchCV(nb_model, param_grid, cv=5)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)
print("Tuned Model Performance:", classification_report(y_test, y_pred_best))

# Sample messages for testing
test_messages = [
    "Congratulations! You've won a $1000 cash prize!",
    "Hey, are we still on for the meeting tomorrow?",
    "Claim your free trial now by clicking this link!",
    "Just checking in. How have you been?",
    "Important: Your account has been compromised. Act now!"
]

# Transform the test messages using the fitted vectorizer
test_vectors = vectorizer.transform(test_messages)

# Predict the classes for the test messages using Naive Bayes
predictions = nb_model.predict(test_vectors)

# Output predictions
for i in range(len(test_messages)):
    label = 'Spam' if predictions[i] == 1 else 'Ham'
    print(f"Message: '{test_messages[i]}' - Prediction: {label}")

